{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ2bG9EX9vx-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "1. 사전 준비 사항\n",
        "Docker Desktop 설치 및 실행\n",
        "\n",
        "Docker 공식 사이트에서 설치 후 실행.\n",
        "\n",
        "Docker가 Linux 컨테이너 모드인지 확인 (Settings > General > Use the WSL 2 based engine 체크).\n",
        "\n",
        "Docker Compose 확인\n",
        "\n",
        "docker-compose는 Docker Desktop에 기본 포함되어 있음.\n",
        "\n",
        "터미널 (PowerShell or WSL)에서 버전 확인:\n",
        "\n",
        "sh\n",
        "docker-compose --version\n",
        "```"
      ],
      "metadata": {
        "id": "Js096OsxAN9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "2. docker-compose.yml 파일 저장\n",
        "위 YAML 파일을 현재 작업 디렉토리에 docker-compose.yml로 저장.\n",
        "```\n"
      ],
      "metadata": {
        "id": "DnfWShJkAVi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "3. Docker 네트워크 설정\n",
        "docker-compose.yml에서 이미 spark-net이라는 bridge 네트워크를 사용하도록 설정되어 있음.\n",
        "```"
      ],
      "metadata": {
        "id": "jOR_QFNAA3HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "4. 컨테이너 실행\n",
        "터미널에서 docker-compose.yml이 있는 디렉토리로 이동 후 실행:\n",
        "\n",
        "sh\n",
        "docker-compose up -d\n",
        "```"
      ],
      "metadata": {
        "id": "XKhetOodBW16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "컨테이너 상태 확인\n",
        "\n",
        "sh\n",
        "docker container -ls\n",
        "```\n"
      ],
      "metadata": {
        "id": "FdmZwtoACTqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "컨테이너 목록"
      ],
      "metadata": {
        "id": "7r4Xl6YwCbti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spark-master\n",
        "\n",
        "spark-worker\n",
        "\n",
        "jupyter"
      ],
      "metadata": {
        "id": "Cp7jil42ATja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "5. 실행된 서비스 접속\n",
        "Spark UI 확인\n",
        "\n",
        "http://localhost:8080 (Spark Master)\n",
        "\n",
        "http://localhost:4040 (Spark Job UI)\n",
        "\n",
        "Jupyter Notebook 접속\n",
        "\n",
        "http://localhost:8888\n",
        "\n",
        "실행 후 제공된 토큰을 사용하여 로그인.\n",
        "\n",
        "Spark Shell 테스트\n",
        "\n",
        "sh\n",
        "docker exec -it spark-master /opt/bitnami/spark/bin/spark-shell --master spark://spark-master:7077\n",
        "실행되면 아래와 같이 확인 가능:\n",
        "\n",
        "scala\n",
        "scala> val data = spark.range(1, 100)\n",
        "scala> data.show()\n",
        "```\n"
      ],
      "metadata": {
        "id": "FiodR9TnCjJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "6. Jupyter에서 Spark 사용 설정\n",
        "Jupyter Notebook에서 pyspark 실행을 위해 새 노트북을 열고 아래 코드 실행:\n",
        "\n",
        "python\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Test\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], [\"id\", \"name\"])\n",
        "df.show()\n",
        "```"
      ],
      "metadata": {
        "id": "St-6ojTjKt_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "7. 컨테이너 정리\n",
        "실행 중인 컨테이너를 중지하고 삭제하려면:\n",
        "\n",
        "sh\n",
        "\n",
        "docker-compose down\n",
        "```"
      ],
      "metadata": {
        "id": "dzl9oGsFNTAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확장\n",
        "\n",
        "Kafka 추가 → 실시간 데이터 스트리밍 처리\n",
        "\n",
        "Zookeeper 추가 → Kafka 클러스터 관리\n",
        "\n",
        "Spark Structured Streaming → Kafka 데이터를 Spark에서 실시간 처리\n",
        "\n",
        "PostgreSQL 추가 → 처리된 데이터를 저장\n",
        "\n",
        "데이터 크롤러 (Scrapy or Python script) → Kafka로 데이터 전송\n",
        "\n"
      ],
      "metadata": {
        "id": "4fg0k7vNNct0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  spark-master:\n",
        "    image: bitnami/spark:3.3.2\n",
        "    container_name: spark-master\n",
        "    ports:\n",
        "      - \"8080:8080\"\n",
        "      - \"4040:4040\"\n",
        "      - \"7077:7077\"\n",
        "    environment:\n",
        "      - SPARK_MODE=master\n",
        "      - SPARK_MASTER_HOST=spark-master\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  spark-worker:\n",
        "    image: bitnami/spark:3.3.2\n",
        "    container_name: spark-worker\n",
        "    environment:\n",
        "      - SPARK_MODE=worker\n",
        "      - SPARK_MASTER_URL=spark://spark-master:7077\n",
        "    depends_on:\n",
        "      - spark-master\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  jupyter:\n",
        "    image: jupyter/pyspark-notebook\n",
        "    container_name: jupyter\n",
        "    ports:\n",
        "      - \"8888:8888\"\n",
        "    depends_on:\n",
        "      - spark-master\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  zookeeper:\n",
        "    image: bitnami/zookeeper:latest\n",
        "    container_name: zookeeper\n",
        "    ports:\n",
        "      - \"2181:2181\"\n",
        "    environment:\n",
        "      - ALLOW_ANONYMOUS_LOGIN=yes\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  kafka:\n",
        "    image: bitnami/kafka:latest\n",
        "    container_name: kafka\n",
        "    ports:\n",
        "      - \"9092:9092\"\n",
        "    environment:\n",
        "      - KAFKA_BROKER_ID=1\n",
        "      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181\n",
        "      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092\n",
        "      - ALLOW_PLAINTEXT_LISTENER=yes\n",
        "    depends_on:\n",
        "      - zookeeper\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  postgres:\n",
        "    image: postgres:latest\n",
        "    container_name: postgres\n",
        "    environment:\n",
        "      POSTGRES_USER: admin\n",
        "      POSTGRES_PASSWORD: admin\n",
        "      POSTGRES_DB: streaming_db\n",
        "    ports:\n",
        "      - \"5432:5432\"\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "  scraper:\n",
        "    build: ./scraper\n",
        "    container_name: scraper\n",
        "    depends_on:\n",
        "      - kafka\n",
        "    networks:\n",
        "      - spark-net\n",
        "\n",
        "networks:\n",
        "  spark-net:\n",
        "    driver: bridge\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tX9sBEbQPgqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "추가된 구성 요소 설명\n",
        "서비스\t설명\n",
        "zookeeper\tKafka 클러스터 관리를 위한 서비스\n",
        "kafka\t실시간 데이터 스트리밍을 위한 메시지 브로커\n",
        "postgres\tSpark에서 처리한 데이터를 저장하는 데이터베이스\n",
        "scraper\t데이터를 크롤링하고 Kafka에 전송하는 Python 서비스\n",
        "```\n"
      ],
      "metadata": {
        "id": "3h204lIiPk6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "scraper/ 디렉토리 생성 후 Dockerfile 추가\n",
        "scraper/Dockerfile:\n",
        "\n",
        "dockerfile\n",
        "\n",
        "FROM python:3.9\n",
        "\n",
        "WORKDIR /app\n",
        "COPY requirements.txt .\n",
        "RUN pip install -r requirements.txt\n",
        "COPY scraper.py .\n",
        "CMD [\"python\", \"scraper.py\"]\n",
        "```"
      ],
      "metadata": {
        "id": "7Dg1N2zWUru_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "크롤러 패키지 설치 (scraper/requirements.txt)\n",
        "\n",
        "txt\n",
        "\n",
        "requests\n",
        "beautifulsoup4\n",
        "kafka-python\n",
        "```"
      ],
      "metadata": {
        "id": "wfuKJOPsUvXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Kafka로 데이터 전송하는 scraper.py 작성 scraper/scraper.py:\n",
        "\n",
        "python\n",
        "\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from kafka import KafkaProducer\n",
        "\n",
        "KAFKA_BROKER = \"kafka:9092\"\n",
        "TOPIC = \"web-data\"\n",
        "\n",
        "producer = KafkaProducer(bootstrap_servers=KAFKA_BROKER)\n",
        "\n",
        "def fetch_data():\n",
        "    url = \"https://news.ycombinator.com/\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    \n",
        "    articles = []\n",
        "    for item in soup.select(\".storylink\"):\n",
        "        articles.append(item.text)\n",
        "\n",
        "    return articles\n",
        "\n",
        "while True:\n",
        "    data = fetch_data()\n",
        "    for article in data:\n",
        "        producer.send(TOPIC, article.encode('utf-8'))\n",
        "    print(\"Data sent to Kafka\")\n",
        "    time.sleep(10)\n",
        "```"
      ],
      "metadata": {
        "id": "PGS9-2UWUzrV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyi6Sf6XCd0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}