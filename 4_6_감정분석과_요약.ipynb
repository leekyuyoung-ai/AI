{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ooGVWwlPpqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화(Tokenization)는 자연어 처리에서 코퍼스를 의미 있는 단위로 나누는 과정입니다. 주요 개념과 고려할 사항은 다음과 같습니다.\n",
        "\n",
        "1. 단어 토큰화 (Word Tokenization)\n",
        "  - 단어를 기준으로 텍스트를 나누는 작업입니다.\n",
        "  - 구두점(punctuation) 제거가 일반적이지만 의미를 잃을 수도 있습니다.\n",
        "  - 영어에서는 아포스트로피 등의 처리 방식이 다를 수 있으며, NLTK, Keras 등을 활용한 다양한 방법이 존재합니다.\n",
        "\n",
        "2. 토큰화 중 선택의 문제\n",
        "  - 예를 들어 \"Don't\"는 Do n't, Dont, Don ' t 등으로 분리할 수 있습니다.\n",
        "  - NLTK의 word_tokenize, WordPunctTokenizer, Keras의 text_to_word_sequence 등의 도구들이 다른 방식으로 토큰화를 수행합니다.\n",
        "\n",
        "3. 토큰화 시 고려 사항\n",
        "  - 구두점이나 특수문자를 무조건 제거하면 의미가 사라질 수 있음.\n",
        "  - 단어 내부에 띄어쓰기가 포함된 경우 고려 필요 (예: \"New York\").\n",
        "  - 표준 토큰화 방식 (예: Penn Treebank Tokenization)에서는 하이픈 단어를 유지하고, 아포스트로피를 분리하는 규칙 적용.\n",
        "\n",
        "4. 문장 토큰화 (Sentence Tokenization)\n",
        "  - 문장을 기준으로 텍스트를 나누는 작업.\n",
        "  - NLTK의 sent_tokenize는 마침표(.)가 포함된 약어(ex. Ph.D.) 등을 적절히 처리함.\n",
        "   -한국어에서는 KSS(Korean Sentence Splitter) 같은 도구를 활용.\n",
        "  \n",
        "5. 한국어에서의 토큰화의 어려움\n",
        "  - 한국어는 교착어 특성상 단순 띄어쓰기 기반 토큰화가 어렵고, 형태소 분석이 필요.\n",
        "  - 형태소 분석기 (KoNLPy의 Okt, Komoran, Hannanum, Mecab) 사용이 일반적."
      ],
      "metadata": {
        "id": "UAT6VQDeZPU3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxMmRDBQZpd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNdQcs6EZXw3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}